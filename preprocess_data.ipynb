{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess NSF OCE award data\n",
    "Created by Ivan Lima on Wed Jan 17 2018 15:47:11 -0500\n",
    "\n",
    "Last modified on Thu Aug 16 2018 16:49:16 -0400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this notebook we remove duplicates records and records with missing abstracts, remove html tags and empty strings from text fields, convert currency strings to numbers, adjust award values for inflation, and compute additional relevant fields for topic modeling of NSF OCE awards**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read award records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data columns:\n",
      "Index(['AwardNumber', 'Title', 'NSFOrganization', 'Program(s)', 'StartDate',\n",
      "       'LastAmendmentDate', 'PrincipalInvestigator', 'State', 'Organization',\n",
      "       'AwardInstrument', 'ProgramManager', 'EndDate', 'AwardedAmountToDate',\n",
      "       'Co-PIName(s)', 'PIEmailAddress', 'OrganizationStreet',\n",
      "       'OrganizationCity', 'OrganizationState', 'OrganizationZip',\n",
      "       'OrganizationPhone', 'NSFDirectorate', 'ProgramElementCode(s)',\n",
      "       'ProgramReferenceCode(s)', 'ARRAAmount', 'Abstract'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "awards = pd.read_csv('data/nsf_oce_awards_1985-2017_clean.csv', parse_dates=[4,5,11], encoding=\"ISO-8859-1\")\n",
    "print('Data columns:\\n{}'.format(awards.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename some variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "awards = awards.rename(index=str, columns={'Program(s)':'Programs',\n",
    "                                           'PrincipalInvestigator':'PI',\n",
    "                                           'AwardInstrument':'Instrument',\n",
    "                                           'AwardedAmountToDate':'Amount',\n",
    "                                           'ARRAAmount':'ARRA',\n",
    "                                           'ProgramElementCode(s)':'ElementCodes',\n",
    "                                           'ProgramReferenceCode(s)':'ReferenceCodes'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute number of Co-PIs for each award"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "awards['num_copi'] = [len(cp.split(',')) if cp not in [np.nan] else np.nan for cp in awards['Co-PIName(s)']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean & preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian probabilistic models are quite sensitive to the input data. Relatively small changes in the collection of documents or on how the *bag-of-words* is built can change some of the topics extracted.\n",
    "\n",
    "**Note:** Collaborative Research awards are those in which investigators from two or more organizations collaborate on one research project. These awards share the same abstract but the different organizations receive separate awards. Here we consider one abstract per project and sum the amounts awarded to each organization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate records: 4755\n",
      "Number of records with missing abstracts: 1212\n",
      "Number of Collaborative Research awards with repeating abstracts: 2660\n",
      "Total removed (missing + duplicate + Collaborative Research): 8627\n",
      "\n",
      "Size of original dataset: 19865 records\n",
      "Size of final preprocessed dataset: 11238 records\n"
     ]
    }
   ],
   "source": [
    "awards['Abstract'][awards.AwardNumber==9421772] = np.nan  # renewal award\n",
    "ntot = len(awards)\n",
    "\n",
    "# remove duplicate records\n",
    "awards_clean = awards.drop_duplicates('AwardNumber')\n",
    "nodup = len(awards_clean)\n",
    "\n",
    "# remove entries with no abstracts\n",
    "awards_clean = awards_clean[awards_clean['Abstract'].notnull()]\n",
    "nomiss = len(awards_clean)\n",
    "\n",
    "# select variables to keep\n",
    "awards_clean = awards_clean[['AwardNumber', 'Title', 'Programs', 'StartDate', 'EndDate', 'ProgramManager',\n",
    "                             'Instrument', 'PI', 'Organization', 'Amount', 'ARRA', 'ElementCodes', 'ReferenceCodes', \n",
    "                             'Abstract', 'num_copi']]\n",
    "\n",
    "# convert currency strings to numbers\n",
    "awards_clean['Amount'] = [np.float(s.replace(',','').lstrip('$')) for s in awards_clean.Amount.values]\n",
    "awards_clean['ARRA']   = [np.float(s.replace(',','').lstrip('$')) for s in awards_clean.ARRA.values]\n",
    "\n",
    "# remove html tags from abstracts\n",
    "awards_clean['Abstract'] = [s.replace('<br/>',' ') for s in awards_clean.Abstract.values]\n",
    "\n",
    "# remove common words\n",
    "for word in ['OCE','ABSTRACT','Abstract','PROJECT','Project']:\n",
    "    awards_clean['Abstract'] = [s.replace(word,' ') for s in awards_clean.Abstract.values]\n",
    "\n",
    "# remove award numbers from abstracts\n",
    "abstracts = awards_clean.Abstract.values\n",
    "for n in awards_clean.AwardNumber.unique():\n",
    "    abstracts = [s.replace(str(n),' ') if str(n) in s else s for s in abstracts]\n",
    "awards_clean['Abstract'] = abstracts\n",
    "\n",
    "# remove empty spaces from abstracts & titles\n",
    "awards_clean['Abstract'] = [' '.join(s.split()) for s in awards_clean.Abstract.values]\n",
    "awards_clean['Title'] = [' '.join(s.split()) for s in awards_clean.Title.values]\n",
    "\n",
    "# clean empty strings from Programs & convert to upper case\n",
    "awards_clean['Programs'] = [','.join(list(filter(bool,s.split(', ')))).upper() \n",
    "                            for s in awards_clean.Programs.fillna('NAN')]\n",
    "awards_clean.loc[awards_clean.Programs=='NAN','Programs'] = np.nan\n",
    "\n",
    "# get number of programs for each award\n",
    "awards_clean['num_programs'] = [len(s.split(',')) for s in awards_clean.Programs.fillna('NAN')]\n",
    "awards_clean.loc[awards_clean.Programs.isnull(),'num_programs'] = np.nan\n",
    "\n",
    "# set award program to first on the list\n",
    "awards_clean['program'] = [s.split(',')[0] for s in awards_clean.Programs.fillna('NAN')]\n",
    "awards_clean.loc[awards_clean.Programs.isnull(),'program'] = np.nan\n",
    "\n",
    "work = awards_clean.drop_duplicates('Abstract')\n",
    "anum = work.AwardNumber.values\n",
    "\n",
    "# sum collaborative research awards into one total amount\n",
    "total = awards_clean.groupby('Abstract')['Amount'].sum()\n",
    "total = total.sort_index()\n",
    "awards_final = awards_clean.drop_duplicates('Abstract')\n",
    "awards_final = awards_final.sort_values('Abstract')\n",
    "awards_final['total_amount'] = total.values\n",
    "awards_final = awards_final.set_index('AwardNumber').loc[anum,:].reset_index()\n",
    "nclean = len(awards_final)\n",
    "\n",
    "print('Number of duplicate records: {}'.format(ntot - nodup))\n",
    "print('Number of records with missing abstracts: {}'.format(nodup - nomiss))\n",
    "print('Number of Collaborative Research awards with repeating abstracts: {}'.format(nomiss - nclean))\n",
    "print('Total removed (missing + duplicate + Collaborative Research): {}\\n'.format(ntot - nclean))\n",
    "print('Size of original dataset: {} records'.format(ntot))\n",
    "print('Size of final preprocessed dataset: {} records'.format(nclean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjust amount awarded for inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpi = pd.read_excel('data/CPI.xlsx', skiprows=range(11), index_col=0) # consumer price index\n",
    "rel_cpi = cpi.Annual/cpi.loc[2017,'Annual']                           # use 2017 as reference year\n",
    "rel_cpi_map = {k:v for k, v in zip(rel_cpi.index, rel_cpi.values)}\n",
    "rel_cpi_map[2018] = 1.0                                               # add 2018\n",
    "awards_final['amount_adjusted'] = awards_final.total_amount / awards_final.StartDate.map(lambda x: rel_cpi_map[x.year])\n",
    "awards_final['arra_adjusted']   = awards_final.ARRA / awards_final.StartDate.map(lambda x: rel_cpi_map[x.year])\n",
    "\n",
    "# remove suspiciously low values (mainly zeros) that might bias the annual means\n",
    "awards_final.loc[awards_final.amount_adjusted<1.e+3,['Amount','amount_adjusted']] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save preprocessed data to HDF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "awards_final = awards_final.reset_index(drop=True)\n",
    "store = pd.HDFStore('data/nsf_oce_awards_1985-2017.h5',complevel=9)\n",
    "store['awards'] = awards_final\n",
    "store.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
